{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/dl-logo.JPG\" width=\"600\"/>\n",
    "\n",
    "***\n",
    "\n",
    "<center>Lecture 7</center>\n",
    "\n",
    "***\n",
    "\n",
    "<center>Time Series Analysis 2</center>  \n",
    "\n",
    "***\n",
    "\n",
    "<center>22 October 2024<center>\n",
    "<center>Rahman Peimankar<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "1. Inputs/outputs of Sequence models (RNNs/LSTMs)\n",
    "2. Deep Learning Based Projects\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap of Last Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-14-lecture8.jpg\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-18-lecture8.JPG\" width=\"900\"/>\n",
    "    \n",
    "$\\hat{y}_t = f(x_t, h_{t-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-27-lecture8.JPG\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-31-lecture8.JPG\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vanishing Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Multiply many **_small numbers_**  -->  Backpropagate further back in time is more difficult due to shrinking gradients of loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Solution 1:** Using ReLU prevents backpropagation derivatives from shrinking the gradients when $x>0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Solution 2:**\n",
    "* Initialize **_weights_** to identify matrix\n",
    "* Initialize **_biases_** to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Solution 3:** **Long Short Term Memory (LSTM)** networks uses the gated cells to control the flow of information throughout many time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Long Short Term Memory (LSTM) Networks\n",
    "\n",
    "Unlike RNNs, LSTM cells contain **computational blocks** that **control information flow**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-1.jpg\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CNNs for Time Series Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-45-lecture8.JPG\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-46-lecture8.jpg\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "# 1. Inputs/outputs of Sequence models (RNNs/LSTMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-2.jpg\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Layer - Conceptual Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-3.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* At each time step, the memory cell takes the input value for that step.\n",
    "* These steps will continue until we reach the end of our input dimension, which in this case has 20 values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-4.png\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The inputs are three dimensional.\n",
    "* For example, if we have a window size of 20 timestamps and we are batching them in sizes of 4, the shape will be $4 \\times 20 \\times 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outputting a Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Other than the state vector ($h$), the each memory cell will also output a $Y$ value.\n",
    "\n",
    "* If the memory cell is comprised of three neurons, then the output matrix will be $4 \\times 3$\n",
    "\n",
    "* So the full output of the layer is three dimensional, in this case, $4 \\times 20 \\times 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-5.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In a simple RNN, the state output $h$ is just a copy of the output matrix $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-6.png\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequence to Vector RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In some cases, you don't want to output all and you want to get a single vector for each instance in the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-7.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* When using Keras in TensorFlow, this is the default behavior. \n",
    "* If you want the recurrent layer to output a sequence, you have to specify ``return_sequences=True``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Graphical Example of ``return_sequences`` parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This RNN, these has two layers.\n",
    "* The first has ``return_sequences=True``. But the second layer does not have a return_sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-8.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rnn_1 (SimpleRNN)           (None, None, 3)           15        \n",
      "                                                                 \n",
      " rnn_2 (SimpleRNN)           (None, 10)                140       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166\n",
      "Trainable params: 166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(3, return_sequences=True, input_shape=[None, 1], name='rnn_1'),\n",
    "    keras.layers.SimpleRNN(10, name='rnn_2'),\n",
    "    keras.layers.Dense(1, name='dense_1')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-8.png\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rnn_1 (LSTM)                (None, None, 10)          480       \n",
      "                                                                 \n",
      " rnn_2 (LSTM)                (None, None, 10)          840       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 1)           11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,331\n",
      "Trainable params: 1,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(10, return_sequences=True, input_shape=[None, 1], name='rnn_1'),\n",
    "    keras.layers.LSTM(10, return_sequences=True, name='rnn_2'),\n",
    "    keras.layers.Dense(1, name='dense_1')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-9.png\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "For the sake of simplicity, we have showed all the examples so far using a ``SimpleRNN`` layer. However, you can easily extend them to an ``LSTM`` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combined CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cnn_1 (Conv1D)              (None, None, 16)          96        \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 10)          1080      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, None, 10)          840       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 3)           33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,049\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=16, kernel_size=5, strides=1, activation='relu', input_shape=[None, 1], name='cnn_1'),\n",
    "    \n",
    "    keras.layers.LSTM(10, return_sequences=True, name='lstm_1'),\n",
    "    keras.layers.LSTM(10, return_sequences=True, name='lstm_2'),\n",
    "    keras.layers.Dense(3, name='dense_1')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-45-lecture8.JPG\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "# 2. Deep Learning Based Projects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Project 1: A Deep Learning Approach for Real-Time Detection of Atrial Fibrillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### What is atrial fibrillation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "\n",
    "<table><tr>\n",
    "<td>\n",
    "    \n",
    "<img src=\"img/Qimage-6-lecture1.png\" width=\"950\"/>\n",
    "    \n",
    "</td>\n",
    "<td>\n",
    "    \n",
    "<img src=\"img/Qimage-7-lecture1.jpg\" width=\"800\"/>\n",
    "    \n",
    "</td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cau you say what type of models can be used for Atrial Fibrillation classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-14-lecture8.jpg\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/Qimage-14-lecture1.png\" width=\"900\"/>\n",
    "</div>\n",
    "    \n",
    "Andersen, Rasmus S., Abdolrahman Peimankar, and Sadasivan Puthusserypady. \"A deep learning approach for real-time detection of atrial fibrillation.\" (https://doi.org/10.1016/j.eswa.2018.08.011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/Qimage-14.JPG\" width=\"1500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/Qimage-10-lecture1.jpg\" width=\"1400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-10.jpg\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-17.JPG\" width=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/Qimage-10-lecture1.jpg\" width=\"1400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-12.jpg\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/Qimage-10-lecture1.jpg\" width=\"1400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-13.jpg\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/Qimage-15.jpg\" width=\"1100\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Results of the trained model on the two test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/Qimage-16.JPG\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Project 2: A Deep Learning Approach for ECG Signal Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-18.jpg\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-19.jpg\" width=\"1400\"/>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Abdolrahman Peimankar and Sadasivan Puthusserypady. \"DENS-ECG: A deep learning approach for ECG signal delineation.\" (https://doi.org/10.1016/j.eswa.2020.113911)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Three consecutive layers of ``1D CNN``!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-20.jpg\" width=\"800\"/>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two ``LSTM`` layers plus the ``Dense`` layer! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-21.jpg\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two excerpts of DENS-ECG model predictions with the corresponding detected P, QRS, T, and NW segments. The true labels (annotations) of the signals are also plotted to compare the results of the classification. (a) A prediction example with high classification rate, (b) A prediction example with some FPs and FNs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-23.jpg\" width=\"1400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-22.jpg\" width=\"1400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Project 3: Activity Classification Using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The aim of this project is to assess physical activity and health outcomes in children and adolescents.\n",
    "\n",
    "* The association between physical activity and energy expenditure should be found using a Machine/Deep Learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-24.PNG\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-25.PNG\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Placement of the different accelerometers.\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"img/Qimage-29.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An overview of the performed activities by the subjects:\n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"img/Qimage-28.JPG\" width=\"1500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* There are two datasets for children and adolescents.\n",
    "* Each dataset has 136,656 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/Qimage-27.png\" width=\"1800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comparison of EE prediction results: Best and worst subjects\n",
    "\n",
    "<center>\n",
    "<img src=\"img/Qimage-31.png\" width=\"500\"/>\n",
    "<img src=\"img/Qimage-32.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/Qimage-33.JPG\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If you would like to do your Master thesis on any of these projects, please contact me (abpe@mmmi.sdu.dk) \n",
    "\n",
    "* You can investigate and improve all the good works, which have done so far.  \n",
    "\n",
    "* Also, if you have an interesting project idea, here you go! Please impress me and we are going to work on it :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* I very much appreciate it if you can please take 10-15 minutes to complete the below feedback survey about this part of the course. \n",
    "\n",
    "\n",
    "* It helps me a lot to improve the lectures in future :-)\n",
    "\n",
    "\n",
    "https://PollEv.com/surveys/cFYIBXI6d2EDvLxYUKnrw/respond"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
